{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":29550,"sourceType":"datasetVersion","datasetId":23079},{"sourceId":61859,"sourceType":"datasetVersion","datasetId":39899}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ==============================\n# 1. IMPORTS\n# ==============================\nimport os\nimport cv2\nimport numpy as np\nfrom time import time\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\nfrom tensorflow.keras.applications import ResNet50V2\nfrom tensorflow.keras.applications.resnet_v2 import preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\n\n# ==============================\n# 2. PARAMETERS\n# ==============================\ntrain_dir = '../input/asl-alphabet/asl_alphabet_train/asl_alphabet_train'\nexternal_test_dir = '/kaggle/input/asl-alphabet-test'\n\nclasses = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', \n           'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', \n           'W', 'X', 'Y', 'Z', 'nothing', 'space', 'del']\n\nnum_classes = len(classes)\nlearning_rate = 1e-4 \ninput_shape = (128, 128, 3)\nbatch_size = 32\nepochs = 20\n\n# ==============================\n# 3. DATA GENERATORS (RESNET PREPROCESSING)\n# ==============================\ntrain_datagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input, # ResNet specific preprocessing (-1 to 1)\n    rotation_range=15,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.1,\n    zoom_range=0.1,\n    horizontal_flip=False,   # Keep False for ASL\n    fill_mode='nearest',\n    validation_split=0.1\n)\n\n# Training generator\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True\n)\n\n# Validation generator\nval_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False\n)\n\n# ==============================\n# 4. MODEL CREATION (RESNET50V2)\n# ==============================\nbase_model = ResNet50V2(weights='imagenet', include_top=False, input_shape=input_shape)\n\n# Freeze bottom 90%, Unfreeze top 10%\nbase_model.trainable = True\nfine_tune_at = int(len(base_model.layers) * 0.9)\n\nfor layer in base_model.layers[:fine_tune_at]:\n    layer.trainable = False\n\nmodel = Sequential([\n    base_model,\n    GlobalAveragePooling2D(),\n    BatchNormalization(),\n    Dense(256, activation='relu'),\n    Dropout(0.5),\n    Dense(num_classes, activation='softmax')\n])\n\nadam = Adam(learning_rate=learning_rate)\nmodel.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()\n\n# ==============================\n# 5. TRAINING WITH CALLBACKS\n# ==============================\nearly_stop = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True, verbose=1)\n\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss', \n    factor=0.2, \n    patience=3, \n    min_lr=1e-6, \n    verbose=1\n)\n\nstart = time()\nhistory = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=epochs,\n    callbacks=[early_stop, reduce_lr],\n    verbose=1\n)\ntrain_time = time() - start\nprint(f\"\\nTraining completed in {train_time:.2f} seconds.\")\n\nmodel.save(\"asl_resnet50v2_optimized.keras\")\nprint(\"Model saved successfully as 'asl_resnet50v2_optimized.keras'!\")\n\n# ==============================\n# 6. PLOT TRAINING HISTORY (NEW SECTION)\n# ==============================\ndef plot_history(history):\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs_range = range(len(acc))\n\n    plt.figure(figsize=(12, 6))\n\n    # Plot Accuracy\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs_range, acc, label='Training Accuracy')\n    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n    plt.legend(loc='lower right')\n    plt.title('Training and Validation Accuracy')\n\n    # Plot Loss\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs_range, loss, label='Training Loss')\n    plt.plot(epochs_range, val_loss, label='Validation Loss')\n    plt.legend(loc='upper right')\n    plt.title('Training and Validation Loss')\n    \n    plt.show()\n\nplot_history(history)\n\n# ==============================\n# 7. EVALUATION ON VALIDATION SET\n# ==============================\ndef evaluate_generator(generator, title=\"Dataset\"):\n    loss, acc = model.evaluate(generator, verbose=1)\n    print(f\"\\n{title} - Accuracy: {acc:.4f}, Loss: {loss:.4f}\")\n\n    y_pred = model.predict(generator, verbose=1)\n    y_pred_labels = np.argmax(y_pred, axis=1)\n    y_true_labels = generator.classes\n\n    cm = confusion_matrix(y_true_labels, y_pred_labels)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n    \n    plt.figure(figsize=(14, 14))\n    disp.plot(xticks_rotation='vertical', cmap='Blues', ax=plt.gca())\n    plt.title(f\"Confusion Matrix - {title}\")\n    plt.show()\n\n    print(f\"\\nCLASSIFICATION REPORT - {title}\")\n    print(classification_report(y_true_labels, y_pred_labels, target_names=classes))\n\nevaluate_generator(val_generator, title=\"Validation Set\")\n\n# ==============================\n# 8. LOAD EXTERNAL TEST DATA\n# ==============================\ndef load_external_test_data(test_dir, img_size=(128, 128)):\n    images, labels = [], []\n    \n    if not os.path.exists(test_dir):\n        print(f\"Error: Directory {test_dir} not found.\")\n        return np.array([]), np.array([])\n\n    for folder in os.listdir(test_dir):\n        if folder not in classes:\n            continue\n            \n        label_idx = classes.index(folder)\n        folder_path = os.path.join(test_dir, folder)\n        \n        for img_name in os.listdir(folder_path):\n            img_path = os.path.join(folder_path, img_name)\n            \n            img = cv2.imread(img_path)\n            \n            if img is None:\n                continue\n            \n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            img = cv2.resize(img, img_size)\n            \n            # ResNet Preprocessing\n            img = img.astype('float32')\n            img = preprocess_input(img) \n            \n            images.append(img)\n            labels.append(label_idx)\n            \n    images = np.array(images)\n    labels = to_categorical(labels, num_classes=num_classes)\n    \n    print(f\"\\nLoaded {images.shape[0]} external test images. Shape = {images.shape}\")\n    return images, labels\n\nx_test_external, y_test_external = load_external_test_data(external_test_dir, img_size=input_shape[:2])\n\n# ==============================\n# 9. EVALUATE ON EXTERNAL TEST SET\n# ==============================\ndef evaluate_on_arrays(x_data, y_data, title=\"External Test Set\"):\n    if x_data.size == 0:\n        print(\"No data to evaluate.\")\n        return\n\n    loss, acc = model.evaluate(x_data, y_data, verbose=1)\n    print(f\"\\n{title} - Accuracy: {acc:.4f}, Loss: {loss:.4f}\")\n\n    y_pred = model.predict(x_data, verbose=1)\n    y_pred_labels = np.argmax(y_pred, axis=1)\n    y_true_labels = np.argmax(y_data, axis=1)\n\n    cm = confusion_matrix(y_true_labels, y_pred_labels)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n    \n    plt.figure(figsize=(14, 14))\n    disp.plot(xticks_rotation='vertical', cmap='Blues', ax=plt.gca())\n    plt.title(f\"Confusion Matrix - {title}\")\n    plt.show()\n\n    print(f\"\\nCLASSIFICATION REPORT - {title}\")\n    print(classification_report(y_true_labels, y_pred_labels, target_names=classes))\n\nevaluate_on_arrays(x_test_external, y_test_external, title=\"External Test Set\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-02T05:39:47.354353Z","iopub.execute_input":"2025-12-02T05:39:47.355279Z","iopub.status.idle":"2025-12-02T05:39:47.361525Z","shell.execute_reply.started":"2025-12-02T05:39:47.355239Z","shell.execute_reply":"2025-12-02T05:39:47.360499Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==============================\n# 1. IMPORTS\n# ==============================\nimport os\nimport cv2\nimport numpy as np\nfrom time import time\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\nfrom tensorflow.keras.applications import ResNet50V2\nfrom tensorflow.keras.applications.resnet_v2 import preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T02:56:39.670832Z","iopub.execute_input":"2025-12-03T02:56:39.671443Z","iopub.status.idle":"2025-12-03T02:56:39.676326Z","shell.execute_reply.started":"2025-12-03T02:56:39.671414Z","shell.execute_reply":"2025-12-03T02:56:39.675494Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==============================\n# 2. PARAMETERS\n# ==============================\ntrain_dir = '../input/asl-alphabet/asl_alphabet_train/asl_alphabet_train'\nexternal_test_dir = '/kaggle/input/asl-alphabet-test'\n\nclasses = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', \n           'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', \n           'W', 'X', 'Y', 'Z', 'nothing', 'space', 'del']\n\nnum_classes = len(classes)\nlearning_rate = 1e-4 \ninput_shape = (128, 128, 3)\nbatch_size = 32\nepochs = 20\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T02:56:51.697844Z","iopub.execute_input":"2025-12-03T02:56:51.698130Z","iopub.status.idle":"2025-12-03T02:56:51.703081Z","shell.execute_reply.started":"2025-12-03T02:56:51.698106Z","shell.execute_reply":"2025-12-03T02:56:51.702243Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==============================\n# 3. DATA GENERATORS (RESNET PREPROCESSING)\n# ==============================\ntrain_datagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input, # ResNet specific preprocessing (-1 to 1)\n    rotation_range=15,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.1,\n    zoom_range=0.1,\n    horizontal_flip=False,   # Keep False for ASL\n    fill_mode='nearest',\n    validation_split=0.1\n)\n\n# Training generator\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True\n)\n\n# Validation generator\nval_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T02:57:15.406237Z","iopub.execute_input":"2025-12-03T02:57:15.406828Z","iopub.status.idle":"2025-12-03T02:57:51.163545Z","shell.execute_reply.started":"2025-12-03T02:57:15.406801Z","shell.execute_reply":"2025-12-03T02:57:51.162820Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==============================\n# 4. MODEL CREATION (RESNET50V2)\n# ==============================\nbase_model = ResNet50V2(weights='imagenet', include_top=False, input_shape=input_shape)\n\n# Freeze bottom 90%, Unfreeze top 10%\nbase_model.trainable = True\nfine_tune_at = int(len(base_model.layers) * 0.9)\n\nfor layer in base_model.layers[:fine_tune_at]:\n    layer.trainable = False\n\nmodel = Sequential([\n    base_model,\n    GlobalAveragePooling2D(),\n    BatchNormalization(),\n    Dense(256, activation='relu'),\n    Dropout(0.5),\n    Dense(num_classes, activation='softmax')\n])\n\nadam = Adam(learning_rate=learning_rate)\nmodel.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T02:57:55.060390Z","iopub.execute_input":"2025-12-03T02:57:55.060705Z","iopub.status.idle":"2025-12-03T02:57:58.928956Z","shell.execute_reply.started":"2025-12-03T02:57:55.060682Z","shell.execute_reply":"2025-12-03T02:57:58.928394Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==============================\n# 5. TRAINING WITH CALLBACKS\n# ==============================\nearly_stop = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True, verbose=1)\n\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss', \n    factor=0.2, \n    patience=3, \n    min_lr=1e-6, \n    verbose=1\n)\n\nstart = time()\nhistory = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=epochs,\n    callbacks=[early_stop, reduce_lr],\n    verbose=1\n)\ntrain_time = time() - start\nprint(f\"\\nTraining completed in {train_time:.2f} seconds.\")\n\nmodel.save(\"asl_resnet50v2_optimized.keras\")\nprint(\"Model saved successfully as 'asl_resnet50v2_optimized.keras'!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T02:58:12.460429Z","iopub.execute_input":"2025-12-03T02:58:12.461039Z","iopub.status.idle":"2025-12-03T04:32:19.715724Z","shell.execute_reply.started":"2025-12-03T02:58:12.461015Z","shell.execute_reply":"2025-12-03T04:32:19.714838Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save(\"asl_resnet50v2_optimized.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T04:37:16.482715Z","iopub.execute_input":"2025-12-03T04:37:16.483230Z","iopub.status.idle":"2025-12-03T04:37:16.997388Z","shell.execute_reply.started":"2025-12-03T04:37:16.483204Z","shell.execute_reply":"2025-12-03T04:37:16.996764Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==============================\n# 6. PLOT TRAINING HISTORY (NEW SECTION)\n# ==============================\ndef plot_history(history):\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs_range = range(len(acc))\n\n    plt.figure(figsize=(12, 6))\n\n    # Plot Accuracy\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs_range, acc, label='Training Accuracy')\n    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n    plt.legend(loc='lower right')\n    plt.title('Training and Validation Accuracy')\n\n    # Plot Loss\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs_range, loss, label='Training Loss')\n    plt.plot(epochs_range, val_loss, label='Validation Loss')\n    plt.legend(loc='upper right')\n    plt.title('Training and Validation Loss')\n    \n    plt.show()\n\nplot_history(history)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T04:38:25.783259Z","iopub.execute_input":"2025-12-03T04:38:25.783794Z","iopub.status.idle":"2025-12-03T04:38:26.145724Z","shell.execute_reply.started":"2025-12-03T04:38:25.783770Z","shell.execute_reply":"2025-12-03T04:38:26.144997Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==============================\n# 7. EVALUATION ON VALIDATION SET\n# ==============================\ndef evaluate_generator(generator, title=\"Dataset\"):\n    loss, acc = model.evaluate(generator, verbose=1)\n    print(f\"\\n{title} - Accuracy: {acc:.4f}, Loss: {loss:.4f}\")\n\n    y_pred = model.predict(generator, verbose=1)\n    y_pred_labels = np.argmax(y_pred, axis=1)\n    y_true_labels = generator.classes\n\n    cm = confusion_matrix(y_true_labels, y_pred_labels)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n    \n    plt.figure(figsize=(14, 14))\n    disp.plot(xticks_rotation='vertical', cmap='Blues', ax=plt.gca())\n    plt.title(f\"Confusion Matrix - {title}\")\n    plt.show()\n\n    print(f\"\\nCLASSIFICATION REPORT - {title}\")\n    print(classification_report(y_true_labels, y_pred_labels, target_names=classes))\n\nevaluate_generator(val_generator, title=\"Validation Set\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T04:39:12.711844Z","iopub.execute_input":"2025-12-03T04:39:12.712392Z","iopub.status.idle":"2025-12-03T04:40:49.564073Z","shell.execute_reply.started":"2025-12-03T04:39:12.712372Z","shell.execute_reply":"2025-12-03T04:40:49.563337Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==============================\n# 8. LOAD EXTERNAL TEST DATA\n# ==============================\ndef load_external_test_data(test_dir, img_size=(128, 128)):\n    images, labels = [], []\n    \n    if not os.path.exists(test_dir):\n        print(f\"Error: Directory {test_dir} not found.\")\n        return np.array([]), np.array([])\n\n    for folder in os.listdir(test_dir):\n        if folder not in classes:\n            continue\n            \n        label_idx = classes.index(folder)\n        folder_path = os.path.join(test_dir, folder)\n        \n        for img_name in os.listdir(folder_path):\n            img_path = os.path.join(folder_path, img_name)\n            \n            img = cv2.imread(img_path)\n            \n            if img is None:\n                continue\n            \n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            img = cv2.resize(img, img_size)\n            \n            # ResNet Preprocessing\n            img = img.astype('float32')\n            img = preprocess_input(img) \n            \n            images.append(img)\n            labels.append(label_idx)\n            \n    images = np.array(images)\n    labels = to_categorical(labels, num_classes=num_classes)\n    \n    print(f\"\\nLoaded {images.shape[0]} external test images. Shape = {images.shape}\")\n    return images, labels\n\nx_test_external, y_test_external = load_external_test_data(external_test_dir, img_size=input_shape[:2])\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T04:41:43.552199Z","iopub.execute_input":"2025-12-03T04:41:43.552504Z","iopub.status.idle":"2025-12-03T04:41:49.708456Z","shell.execute_reply.started":"2025-12-03T04:41:43.552482Z","shell.execute_reply":"2025-12-03T04:41:49.707537Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==============================\n# 9. EVALUATE ON EXTERNAL TEST SET\n# ==============================\ndef evaluate_on_arrays(x_data, y_data, title=\"External Test Set\"):\n    if x_data.size == 0:\n        print(\"No data to evaluate.\")\n        return\n\n    loss, acc = model.evaluate(x_data, y_data, verbose=1)\n    print(f\"\\n{title} - Accuracy: {acc:.4f}, Loss: {loss:.4f}\")\n\n    y_pred = model.predict(x_data, verbose=1)\n    y_pred_labels = np.argmax(y_pred, axis=1)\n    y_true_labels = np.argmax(y_data, axis=1)\n\n    cm = confusion_matrix(y_true_labels, y_pred_labels)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n    \n    plt.figure(figsize=(14, 14))\n    disp.plot(xticks_rotation='vertical', cmap='Blues', ax=plt.gca())\n    plt.title(f\"Confusion Matrix - {title}\")\n    plt.show()\n\n    print(f\"\\nCLASSIFICATION REPORT - {title}\")\n    print(classification_report(y_true_labels, y_pred_labels, target_names=classes))\n\nevaluate_on_arrays(x_test_external, y_test_external, title=\"External Test Set\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T04:41:49.709778Z","iopub.execute_input":"2025-12-03T04:41:49.710307Z","iopub.status.idle":"2025-12-03T04:42:03.150848Z","shell.execute_reply.started":"2025-12-03T04:41:49.710283Z","shell.execute_reply":"2025-12-03T04:42:03.150117Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}